/* This file is auto-generated by `just build-migrations`; DO NOT EDIT */
export const getMigrations = (schemaName: string) => ({
  "0000000000_migrations.sql": String.raw`
DO $$
BEGIN
  IF NOT EXISTS (SELECT 1 FROM pg_extension WHERE extname = 'uuid-ossp') THEN
    RAISE EXCEPTION 'Extension uuid-ossp is not installed. Run: CREATE EXTENSION "uuid-ossp";';
  END IF;
END $$;

CREATE SCHEMA IF NOT EXISTS pgconductor;

CREATE TABLE pgconductor.schema_migrations (
  version INT PRIMARY KEY,
  name TEXT NOT NULL,
  applied_at TIMESTAMP DEFAULT NOW(),
  breaking boolean default false
);
`,
  "0000000001_setup.sql": String.raw`

create extension if not exists "uuid-ossp";

-- Returns either the actual current timestamp or a fake one for tests.
-- Uses session variable (current_setting) for test time control.
create function pgconductor.current_time ()
  returns timestamptz
  language plpgsql
  volatile
as $$
declare
  v_fake text;
begin
  v_fake := current_setting('pgconductor.fake_now', true);
  if v_fake is not null and length(trim(v_fake)) > 0 then
    return v_fake::timestamptz;
  end if;

  return clock_timestamp();
end;
$$;

-- utility function to generate a uuidv7 even for older postgres versions.
create function pgconductor.portable_uuidv7 ()
  returns uuid
  language plpgsql
  volatile
as $$
declare
  v_server_num integer := current_setting('server_version_num')::int;
  ts_ms bigint;
  b bytea;
  rnd bytea;
  i int;
begin
  if v_server_num >= 180000 then
    return uuidv7 ();
  end if;
  ts_ms := floor(extract(epoch from pgconductor.current_time()) * 1000)::bigint;
  rnd := uuid_send(public.uuid_generate_v4 ());
  b := repeat(E'\\000', 16)::bytea;
  for i in 0..5 loop
    b := set_byte(b, i, ((ts_ms >> ((5 - i) * 8)) & 255)::int);
  end loop;
  for i in 6..15 loop
    b := set_byte(b, i, get_byte(rnd, i));
  end loop;
  b := set_byte(b, 6, ((get_byte(b, 6) & 15) | (7 << 4)));
  b := set_byte(b, 8, ((get_byte(b, 8) & 63) | 128));
  return encode(b, 'hex')::uuid;
end;
$$;

create table pgconductor.orchestrators (
    id uuid default pgconductor.portable_uuidv7() primary key,
    last_heartbeat_at TIMESTAMPTZ NOT NULL DEFAULT NOW(),
    version text,
    migration_number integer
);

create index idx_orchestrators_heartbeat on pgconductor.orchestrators (last_heartbeat_at);
create index idx_orchestrators_sweep on pgconductor.orchestrators (migration_number);

create table pgconductor.orchestrator_signals (
    id uuid primary key default pgconductor.portable_uuidv7(),
    orchestrator_id uuid not null references pgconductor.orchestrators(id) on delete cascade,
    type text not null,
    execution_id uuid,
    payload jsonb not null default '{}'::jsonb,
    created_at timestamptz not null default pgconductor.current_time()
);

create index idx_orchestrator_signals_orchestrator on pgconductor.orchestrator_signals(orchestrator_id, created_at);

create unique index idx_orchestrator_signals_cancel_unique
    on pgconductor.orchestrator_signals(orchestrator_id, execution_id)
    where type = 'cancel_execution' and execution_id is not null;

create unique index idx_orchestrator_signals_shutdown_unique
    on pgconductor.orchestrator_signals(orchestrator_id)
    where type = 'shutdown';

create table pgconductor.queues (
    name text primary key
);

create table pgconductor.executions (
    id uuid default pgconductor.portable_uuidv7(),
    task_key text not null,
    queue text not null default 'default',
    dedupe_key text,
    cron_expression text,
    created_at timestamptz default pgconductor.current_time() not null,
    failed_at timestamptz,
    completed_at timestamptz,
    payload jsonb,
    run_at timestamptz default pgconductor.current_time() not null,
    locked_at timestamptz,
    locked_by uuid,
    is_available boolean generated always as (locked_at is null and failed_at is null and completed_at is null) stored not null,
    attempts integer default 0 not null,
    last_error text,
    cancelled boolean default false not null,
    priority integer default 0 not null,
    waiting_on_execution_id uuid,
    waiting_step_key text,
    parent_execution_id uuid,
    primary key (id, queue),
    unique (task_key, dedupe_key, queue)
) partition by list (queue);

create table pgconductor.tasks (
    key text primary key,

    -- queue that this task belongs to (used for queue-based worker assignment)
    queue text default 'default' not null,

    -- retry settings - uses fixed Inngest-style backoff schedule
    max_attempts integer default 3 not null,

    -- retention settings: NULL=keep forever, 0=delete immediately, N=delete after N days
    remove_on_complete_days integer,
    remove_on_fail_days integer,

    -- task can be executed only within certain time windows
    -- e.g. business hours, weekends, nights, ...
    -- we will stop the execution of executions outside of these time windows at step boundaries
    window_start timetz,
    window_end timetz,
    constraint "windows" check (
        (window_start is null and window_end is null) or
        (
            window_start is not null and
            window_end is not null and
            window_start != window_end
        )
    )
);

create table pgconductor.steps (
    id uuid default pgconductor.portable_uuidv7() primary key,
    key text not null,
    execution_id uuid not null,
    queue text not null,
    result jsonb,
    created_at timestamptz default pgconductor.current_time() not null,
    unique (key, execution_id),
    constraint fk_execution foreign key (execution_id, queue) references pgconductor.executions(id, queue) on delete cascade
);

create index idx_steps_execution_id on pgconductor.steps (execution_id);

-- Trigger function to manage executions partitions per queue
-- Automatically creates partition when queue is inserted
create or replace function pgconductor.manage_queue_partition()
 returns trigger
 language plpgsql
 volatile
 set search_path to ''
as $function$
declare
  v_partition_name text;
begin
  if tg_op = 'INSERT' then
    v_partition_name := 'executions_' || replace(new.name, '-', '_');

    -- Create partition for this queue: executions_default, executions_reports, etc.
    execute format(
      'create table if not exists pgconductor.%I partition of pgconductor.executions for values in (%L) with (fillfactor=70)',
      v_partition_name,
      new.name
    );

    -- create indices

    -- main index for fetching available executions
    execute format(
      'create index if not exists %I on pgconductor.%I (priority, run_at) include (id, task_key) where is_available = true',
      'idx_' || v_partition_name || '_get_executions',
      v_partition_name
    );

    -- index for waiting executions lookup
    execute format(
      'create index if not exists %I on pgconductor.%I (waiting_on_execution_id) where waiting_on_execution_id is not null',
      'idx_' || v_partition_name || '_waiting_on_execution_id',
      v_partition_name
    );

    -- index for parent execution lookup (child -> parent)
    execute format(
      'create index if not exists %I on pgconductor.%I (parent_execution_id) where parent_execution_id is not null',
      'idx_' || v_partition_name || '_parent_execution_id',
      v_partition_name
    );

    -- index for unlocking locked executions
    execute format(
      'create index if not exists %I on pgconductor.%I (locked_by) where locked_by is not null',
      'idx_' || v_partition_name || '_locked_by',
      v_partition_name
    );

    -- index for cleanup of completed
    execute format(
      'create index if not exists %I on pgconductor.%I (completed_at) where completed_at is not null',
      'idx_' || v_partition_name || '_completed_cleanup',
      v_partition_name
    );

    -- index for cleanup of failed
    execute format(
      'create index if not exists %I on pgconductor.%I (failed_at) where failed_at is not null',
      'idx_' || v_partition_name || '_failed_cleanup',
      v_partition_name
    );

    -- index for dynamic schedule lookups
    execute format(
      'create index if not exists %I on pgconductor.%I ((split_part(dedupe_key, ''::'', 2))) where dedupe_key like ''dynamic::%%'' and cron_expression is not null',
      'idx_' || v_partition_name || '_dynamic_schedule',
      v_partition_name
    );

    -- index for task_key joins (used in return_executions)
    execute format(
      'create index if not exists %I on pgconductor.%I (task_key)',
      'idx_' || v_partition_name || '_task_key',
      v_partition_name
    );

    RETURN NEW;

  elsif tg_op = 'UPDATE' then
    -- protect default queue from modification
    if old.name = 'default' or new.name = 'default' then
      raise exception 'Modifying the default queue is not allowed';
    end if;

    -- disallow renaming queues
    if new.name != old.name then
      raise exception 'Renaming queues is not allowed. Queue name cannot be changed from % to %', old.name, new.name;
    end if;

    return new;

  elsif tg_op = 'DELETE' then
    -- protect default queue from deletion
    if old.name = 'default' then
      raise exception 'Deleting the default queue is not allowed';
    end if;

    v_partition_name := 'executions_' || replace(old.name, '-', '_');

    -- drop the partition for this queue
    execute format(
      'drop table if exists pgconductor.%I',
      v_partition_name
    );

    return old;
  end if;
end;
$function$;

-- attach trigger to queues table
create trigger manage_queue_partition_trigger
  after insert or update or delete on pgconductor.queues
  for each row
  execute function pgconductor.manage_queue_partition();

-- create default queue (trigger will create executions_default partition)
insert into pgconductor.queues (name) values ('default');

create table if not exists pgconductor.subscriptions (
    id uuid primary key default pgconductor.portable_uuidv7(),
    source text not null, -- 'db' or 'event'
    schema_name text,
    table_name text,
    operation text, -- 'insert', 'update', 'delete'
    event_key text,
    execution_id uuid, -- null for trigger-based (persistent) subscriptions
    queue text not null default 'default',
    step_key text, -- step key to save result to when event arrives; null = persistent
    task_key text, -- task to invoke for trigger-based subscriptions
    columns text[] -- columns to select for db events
);

create index if not exists idx_subscriptions_triggers_lookup
on pgconductor.subscriptions (schema_name, table_name, operation);

create table if not exists pgconductor.events (
    id uuid primary key default pgconductor.portable_uuidv7(),
    event_key text not null,
    schema_name text,
    table_name text,
    operation text,
    source text not null default 'event', -- 'db' or 'event'
    payload jsonb,
    created_at timestamptz default pgconductor.current_time() not null
);
-- todo: partition management

-- we would need to extract columns the user filters on to filter event payloads already here
create table if not exists pgconductor.triggers (
    schema_name text not null,
    table_name text not null,
    operation text not null, -- 'insert', 'update', 'delete'
    created_at timestamptz default pgconductor.current_time() not null,
    primary key (schema_name, table_name, operation)
);

create or replace function pgconductor.publish_event ()
    returns trigger
    language plpgsql
    security definer
    as $$
begin
    insert into pgconductor.events(
       event_key,
       schema_name,
       table_name,
       operation,
       source,
       payload
    )
    values (
        tg_table_schema || '.' || tg_table_name || '.' || tg_op,
        tg_table_schema,
        tg_table_name,
        tg_op,
        'db',
        jsonb_build_object(
            'tg_op', tg_op,
            'old', to_jsonb(old),
            'new', to_jsonb(new)
        )
    );
    return new;
end
$$;

create or replace function pgconductor.sync_database_trigger() returns "trigger"
    language "plpgsql" security definer
    as $_$
declare
    v_table_name text := coalesce(new.table_name, old.table_name);
    v_schema_name text := coalesce(new.schema_name, old.schema_name);
    v_op text := coalesce(new.operation, old.operation);
begin
    if tg_op = 'INSERT' then
        execute format(
            $sql$
                create constraint trigger pgconductor_after_%s
                after %s on %I.%I
                deferrable initially deferred
                for each row
                execute procedure pgconductor.publish_event()
            $sql$,
            lower(v_op), lower(v_op), v_schema_name, v_table_name
        );
    end if;

    if tg_op = 'DELETE' then
        execute format(
            $sql$drop trigger if exists pgconductor_after_%s on %I.%I;$sql$,
            lower(v_op), v_schema_name, v_table_name
        );
    end if;

    return new;
end
$_$;

create or replace trigger "sync_database_trigger"
after insert or delete
on pgconductor.triggers
for each row execute function pgconductor.sync_database_trigger();

-- drop a queue (will trigger partition deletion via trigger)
create or replace function pgconductor.drop_queue(queue_name text)
 returns void
 language sql
 volatile
 set search_path to ''
as $function$
  delete from pgconductor.queues where name = drop_queue.queue_name;
$function$;

create type pgconductor.execution_spec as (
    task_key text,
    queue text,
    payload jsonb,
    run_at timestamptz,
    dedupe_key text,
    cron_expression text,
    priority integer
);

create type pgconductor.task_spec as (
    key text,
    queue text,
    max_attempts integer,
    remove_on_complete_days integer,
    remove_on_fail_days integer,
    window_start timetz,
    window_end timetz
);

create type pgconductor.subscription_spec as (
    task_key text,
    queue text,
    source text,
    event_key text,
    schema_name text,
    table_name text,
    operation text,
    columns text[]
);

create or replace function pgconductor.register_worker(
    p_queue_name text,
    p_task_specs pgconductor.task_spec[],
    p_cron_schedules pgconductor.execution_spec[],
    p_event_subscriptions pgconductor.subscription_spec[] default array[]::pgconductor.subscription_spec[]
)
returns void
language plpgsql
volatile
set search_path to ''
as $function$
begin
  -- step 1: upsert queue (triggers partition creation)
  insert into pgconductor.queues (name)
  values (p_queue_name)
  on conflict (name) do nothing;

  -- step 2: register/update tasks
  insert into pgconductor.tasks (key, queue, max_attempts, remove_on_complete_days, remove_on_fail_days, window_start, window_end)
  select
    spec.key,
    coalesce(spec.queue, 'default'),
    coalesce(spec.max_attempts, 3),
    spec.remove_on_complete_days,
    spec.remove_on_fail_days,
    spec.window_start,
    spec.window_end
  from unnest(p_task_specs) as spec
  on conflict (key)
  do update set
    queue = coalesce(excluded.queue, pgconductor.tasks.queue),
    max_attempts = coalesce(excluded.max_attempts, pgconductor.tasks.max_attempts),
    remove_on_complete_days = excluded.remove_on_complete_days,
    remove_on_fail_days = excluded.remove_on_fail_days,
    window_start = excluded.window_start,
    window_end = excluded.window_end;

  -- step 3: insert scheduled cron executions (on conflict do nothing)
  insert into pgconductor.executions (task_key, queue, payload, run_at, dedupe_key, cron_expression)
  select
    spec.task_key,
    coalesce(spec.queue, 'default'),
    coalesce(spec.payload, '{}'::jsonb),
    coalesce(spec.run_at, pgconductor.current_time()),
    spec.dedupe_key,
    spec.cron_expression
  from unnest(p_cron_schedules) as spec
  where spec.dedupe_key is not null
  on conflict (task_key, dedupe_key, queue) do nothing;

  -- step 4: clean up stale schedules for this queue
  -- delete future executions for schedules that no longer exist
  delete from pgconductor.executions
  where queue = p_queue_name
    and cron_expression is not null
    and run_at > pgconductor.current_time()
    and dedupe_key like 'scheduled::%'
    and split_part(dedupe_key, '::', 2) not in (
      select split_part(spec.dedupe_key, '::', 2)
      from unnest(p_cron_schedules) as spec
      where spec.dedupe_key is not null and spec.dedupe_key like 'scheduled::%'
    );

  -- mark running executions as cancelled for schedules that no longer exist
  update pgconductor.executions
  set cancelled = true
  where queue = p_queue_name
    and cron_expression is not null
    and dedupe_key like 'scheduled::%'
    and locked_by is not null
    and completed_at is null
    and failed_at is null
    and cancelled = false
    and split_part(dedupe_key, '::', 2) not in (
      select split_part(spec.dedupe_key, '::', 2)
      from unnest(p_cron_schedules) as spec
      where spec.dedupe_key is not null and spec.dedupe_key like 'scheduled::%'
    );

  -- step 5: delete old trigger-based subscriptions for this queue
  delete from pgconductor.subscriptions
  where queue = p_queue_name
    and step_key is null  -- only persistent/trigger subscriptions
    and task_key is not null;

  -- step 6: insert new trigger-based subscriptions
  insert into pgconductor.subscriptions (
    task_key, queue, source, event_key, schema_name, table_name, operation, columns
  )
  select
    spec.task_key,
    spec.queue,
    spec.source,
    spec.event_key,
    spec.schema_name,
    spec.table_name,
    spec.operation,
    spec.columns
  from unnest(p_event_subscriptions) as spec;

 -- step 7: make sure we sync database triggers if required
 insert into pgconductor.triggers (schema_name, table_name, operation)
  select
    spec.schema_name,
    spec.table_name,
    spec.operation
  from unnest(p_event_subscriptions) as spec
  where spec.schema_name is not null
  on conflict (schema_name, table_name, operation) do nothing;
end;
$function$;

create or replace function pgconductor.invoke_batch(
    specs pgconductor.execution_spec[]
)
 returns table(id uuid)
 language plpgsql
 volatile
 set search_path to ''
as $function$
begin
    -- clear locked dedupe keys before batch insert
    update pgconductor.executions as e
    set
        dedupe_key = null,
        locked_by = null,
        locked_at = null,
        failed_at = pgconductor.current_time(),
        last_error = 'superseded by reinvoke'
    from unnest(specs) as spec
    where e.dedupe_key = spec.dedupe_key
        and e.task_key = spec.task_key
        and e.queue = coalesce(spec.queue, 'default')
        and e.locked_at is not null
        and spec.dedupe_key is not null;

    -- batch insert all executions
    return query
    insert into pgconductor.executions (
        id,
        task_key,
        queue,
        payload,
        run_at,
        dedupe_key,
        cron_expression,
        priority
    )
    select
        pgconductor.portable_uuidv7(),
        spec.task_key,
        coalesce(spec.queue, 'default'),
        spec.payload,
        coalesce(spec.run_at, pgconductor.current_time()),
        spec.dedupe_key,
        spec.cron_expression,
        coalesce(spec.priority, 0)
    from unnest(specs) as spec
    returning id;
end;
$function$
;

create or replace function pgconductor.invoke(
    task_key text,
    queue text default 'default',
    payload jsonb default null,
    run_at timestamptz default null,
    dedupe_key text default null,
    cron_expression text default null,
    priority integer default null
)
 returns table(id uuid)
 language plpgsql
 volatile
 set search_path to ''
as $function$
begin
  if invoke.dedupe_key is not null then
      -- clear keys that are currently locked so a subsequent insert can succeed.
      update pgconductor.executions as e
      set
        dedupe_key = null,
        locked_by = null,
        locked_at = null,
        failed_at = pgconductor.current_time(),
        last_error = 'superseded by reinvoke'
      where e.dedupe_key = invoke.dedupe_key
        and e.task_key = invoke.task_key
        and e.queue = invoke.queue
        and e.locked_at is not null;
  end if;

  return query insert into pgconductor.executions as e (
    id,
    task_key,
    queue,
    payload,
    run_at,
    dedupe_key,
    cron_expression,
    priority
  ) values (
    pgconductor.portable_uuidv7(),
    invoke.task_key,
    invoke.queue,
    invoke.payload,
    coalesce(invoke.run_at, pgconductor.current_time()),
    invoke.dedupe_key,
    invoke.cron_expression,
    coalesce(invoke.priority, 0)
  ) returning e.id;
end;
$function$
;

-- invoke a task from an event trigger
-- called by event-router when event arrives for trigger-based (persistent) subscriptions
create or replace function pgconductor.invoke_from_event(
    p_task_key text,
    p_queue text,
    p_event_name text,
    p_payload jsonb
)
returns uuid
language sql
volatile
set search_path to ''
as $function$
    insert into pgconductor.executions (
        task_key,
        queue,
        payload,
        run_at
    )
    values (
        p_task_key,
        p_queue,
        jsonb_build_object('event', p_event_name, 'payload', p_payload),
        pgconductor.current_time()
    )
    returning id;
$function$;

-- emit a custom event
create or replace function pgconductor.emit_event(
    p_event_key text,
    p_payload jsonb default null
)
returns uuid
language sql
volatile
set search_path to ''
as $function$
    insert into pgconductor.events (event_key, payload)
    values (p_event_key, p_payload)
    returning id;
$function$;

-- cancel an execution
create or replace function pgconductor.cancel_execution(
  p_execution_id uuid,
  p_reason text default 'Cancelled by user'
)
returns boolean
language plpgsql
volatile
set search_path to ''
as $function$
declare
  v_orchestrator_id uuid;
  v_queue text;
  v_completed boolean;
  v_failed boolean;
  v_rows_affected integer;
begin
  select
    locked_by,
    queue,
    completed_at is not null,
    failed_at is not null
  into v_orchestrator_id, v_queue, v_completed, v_failed
  from pgconductor.executions
  where id = p_execution_id;

  if not found or v_completed or v_failed then
    return false;
  end if;

  if v_orchestrator_id is null then
    -- pending: fail immediately
    update pgconductor.executions
    set
      failed_at = pgconductor.current_time(),
      last_error = p_reason,
      locked_by = null,
      locked_at = null
    where id = p_execution_id
      and completed_at is null
      and failed_at is null;

    get diagnostics v_rows_affected = row_count;
    return v_rows_affected > 0;
  else
    -- running: signal orchestrator + set cancelled flag
    update pgconductor.executions
    set
      cancelled = true,
      last_error = p_reason
    where id = p_execution_id
      and completed_at is null
      and cancelled = false;

    get diagnostics v_rows_affected = row_count;

    if v_rows_affected > 0 then
      insert into pgconductor.orchestrator_signals
        (orchestrator_id, type, execution_id, payload)
      values (
        v_orchestrator_id,
        'cancel_execution',
        p_execution_id,
        jsonb_build_object('queue', v_queue, 'reason', p_reason)
      )
      on conflict (orchestrator_id, execution_id)
        where type = 'cancel_execution' and execution_id is not null
      do nothing;

      return true;
    else
      return false;
    end if;
  end if;
end;
$function$;
`,
});
